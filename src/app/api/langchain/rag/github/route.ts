import { ChatAnthropic } from '@langchain/anthropic';
import { PromptTemplate } from '@langchain/core/prompts';
import { GithubRepoLoader } from '@langchain/community/document_loaders/web/github';
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import { MemoryVectorStore } from "langchain/vectorstores/memory";
import { FakeListChatModel } from '@langchain/core/utils/testing';
import { ChatOpenAI, OpenAI, OpenAIEmbeddings } from '@langchain/openai';
import { Message as VercelChatMessage, LangChainAdapter } from 'ai';
 
// ãƒãƒ£ãƒƒãƒˆå½¢å¼
const formatMessage = (message: VercelChatMessage) => {
  return `${message.role}: ${message.content}`;
};

// ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
const TEMPLATE = `3è¡Œã«ã¾ã¨ã‚ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
Current conversation:
{chat_history}
 
user: {input}
assistant:`;

/**
 * ãƒãƒ£ãƒƒãƒˆå¿œç­”AIï¼ˆè¨˜æ†¶ãƒ»ãƒ¢ãƒ‡ãƒ«å¤‰æ›´å¯¾å¿œæ¸ˆã¿ï¼‰
 * @param req 
 * @returns 
 */
export async function POST(req: Request) {
  try{
    const body = await req.json();
    const messages = body.messages ?? [];
    const modelName = body.model ?? 'fake-llm';

    /**
     * RAGã‚’è©¦ã™
     */
    // document Loaderã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
    console.log("Load GitHub Repository");
    const loader = new GithubRepoLoader(
      "https://github.com/langchain-ai/langchain", 
      {
        branch: "master",
        recursive: true,
        accessToken: process.env.GITHUB_TOKEN,
        unknown: "warn",
      ignoreFiles: [/^(?!.*\.(js|ts)$).*$/],
      }
    );
    const docs = await loader.load();

    // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰² & ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    console.log("Split & Embed Documents");
    const splitter = new RecursiveCharacterTextSplitter({
      chunkSize: 1000,
      chunkOverlap: 0,
    });
    const splitDocs = await splitter.splitDocuments(docs);
    
    const embeddings = new OpenAIEmbeddings({apiKey: process.env.OPENAI_API_KEY});
    const vectorStore = await MemoryVectorStore.fromDocuments(
      splitDocs,
      embeddings
    );


    // éå»ã®å±¥æ­´{chat_history}
    const formattedPreviousMessages = messages
      .slice(0, -1)
      .map(formatMessage)

    // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸{input}
    const currentMessageContent = messages[messages.length - 1].content;

    // ãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®š
    let model;
    switch (modelName) {
      case 'gpt-4o':
        model = new ChatOpenAI({
        apiKey: process.env.OPENAI_API_KEY!,
        model: 'gpt-4o-mini',
        temperature: 0.9, // ãƒ©ãƒ³ãƒ€ãƒ åº¦ï¼ˆé«˜ã„ã»ã©å‰µé€ çš„ï¼‰
        });
      break;
      case 'claude-haiku':
        model = new ChatAnthropic({
          model: 'claude-3-5-haiku-20241022',
          temperature: 0.9, // ãƒ©ãƒ³ãƒ€ãƒ åº¦ï¼ˆé«˜ã„ã»ã©å‰µé€ çš„ï¼‰
        });
      break;
      default:
        model = new FakeListChatModel({
          responses: [
            "ï¼ˆå¿œç­”çµæœï¼‰",
          ],
        });
    }
        
    const prompt = PromptTemplate.fromTemplate(TEMPLATE);
    const chain = prompt.pipe(model);

    // Retriever ã‚’ç”¨ã„ã¦ã€Vectore Store ã‹ã‚‰æ¤œç´¢ã—è¿”ç­”
    const retriever = vectorStore.asRetriever({ k: 3 });

    // ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰
    // const qaChain = RunnableSequence.from([
    //   async (input: string) => {
    //     const docs = await retriever.getRelevantDocuments(input);
    //     console.log(docs);
    //     const context = docs.map((d) => d.pageContent).join("\n\n");
    //     return `ä»¥ä¸‹ã®æ–‡è„ˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„:\n\n${context}\n\nè³ªå•: ${input}`;
    //   },
    //   (prompt) => model.invoke(prompt),
    // ])

    

    const question = "AWSã®S3ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®Document loaderã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ";
    const response = await retriever.invoke(question);

    console.log("ğŸ§  å›ç­”:", response);


    const stream = await chain.stream({
      chat_history: formattedPreviousMessages.join('\n'),
      input: currentMessageContent,
    });



    return LangChainAdapter.toDataStreamResponse(stream);
  } catch (error) {
    if (error instanceof Error) {
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      });
    }
 
    return new Response(
      JSON.stringify({ error: 'Unknown error occurred' }),
      { status: 500, headers: { 'Content-Type': 'application/json' } },
    );
  }
}