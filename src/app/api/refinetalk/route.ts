import { PromptTemplate } from "@langchain/core/prompts";
import { Message as VercelChatMessage, LangChainAdapter } from "ai";
import { StringOutputParser } from "@langchain/core/output_parsers";
import { ChatAnthropic } from "@langchain/anthropic";
import { Client } from "langsmith";

import { cutKeyword } from "@/contents/utils";

const client = new Client({
  apiKey: process.env.LANGSMITH_API_KEY,
});

const model = new ChatAnthropic({
  model: "claude-3-5-haiku-latest",
  apiKey: process.env.ANTHROPIC_API_KEY,
  tags: ["refinetalk"],
  temperature: 0.3,
});

const MARKDOWN_NAME = [
  "q1_morning-meeting.md",
  "q2_group-info.md",
  "q3_slide-review.md",
  "q4_meeting-report.md",
  "q5_phone-call.md",
  "q6_email-report.md",
];

/**
 * RefineTalk API
 * å ±å‘Šã«å¯¾ã™ã‚‹ãƒ“ã‚¸ãƒã‚¹ãƒãƒŠãƒ¼ã®æŒ‡æ‘˜
 * @param req
 * @returns
 */
export async function POST(req: Request) {
  try {
    // ãƒãƒ£ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    const body = await req.json();
    const messages = body.messages ?? [];
    const page = req.headers.get("page");

    console.log("ğŸ§  AI è©•ä¾¡é–‹å§‹...");

    // ãƒãƒ£ãƒƒãƒˆå½¢å¼
    const formatMessage = (message: VercelChatMessage) => {
      return `${message.role}: ${message.content}`;
    };

    // éå»ã®å±¥æ­´ {chat_history}ç”¨
    const formattedPreviousMessages = messages.slice(0, -1).map(formatMessage);
    //ç¾åœ¨ã®å±¥æ­´ {input}ç”¨
    const currentMessageContent = messages[messages.length - 1].content;

    // pageæ•°ã®å–å¾—
    let markdownPage = Number(page);
    if (isNaN(markdownPage)) {
      markdownPage = 0;
    }
    console.log("ãƒšãƒ¼ã‚¸æ•°: " + markdownPage);

    console.log("ğŸ“ƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾—é–‹å§‹...");
    // langsmithã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾—
    const characterTemplate = await client.pullPromptCommit(
      "refine-talk-character"
    );
    const scoreTemplate = await client.pullPromptCommit("refine-talk-scere");

    // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾—
    const characterPrompt = PromptTemplate.fromTemplate(
      characterTemplate.manifest.kwargs.template
    );
    const scorePrompt = PromptTemplate.fromTemplate(
      scoreTemplate.manifest.kwargs.template
    );

    // å‡ºåŠ›å½¢å¼ã®æŒ‡å®š
    const outputParser = new StringOutputParser();

    // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã‚’ã¤ãªã
    const firstChain = scorePrompt.pipe(model).pipe(outputParser);
    const secondChain = characterPrompt.pipe(model).pipe(outputParser);

    console.log("1âƒ£  ç‚¹æ•°ã®å–å¾—ä¸­...");

    // 1å›ç›®ã®è³ªå•
    const getScore = await firstChain.invoke({
      input: currentMessageContent,
    });
    console.log("score: " + getScore);

    // æ–‡å­—åˆ—ã®åˆ‡ã‚Šå‡ºã—
    const score = cutKeyword(getScore, "ç·åˆç‚¹: ");
    const checkPoint = cutKeyword(score, "æŒ‡æ‘˜ãƒã‚¤ãƒ³ãƒˆ: ");

    console.log("2âƒ£  è©•ä¾¡ã®å–å¾—ä¸­...");

    // 2å›ç›®ã®è³ªå•
    const stream = await secondChain.stream({
      history: formattedPreviousMessages.join("\n"),
      question: MARKDOWN_NAME[markdownPage],
      input: currentMessageContent,
      score: score,
      prompt1_output: checkPoint,
    });

    return LangChainAdapter.toDataStreamResponse(stream);
  } catch (error) {
    if (error instanceof Error) {
      console.log(error);
      return new Response(JSON.stringify({ error: error.message }), {
        status: 500,
        headers: { "Content-Type": "application/json" },
      });
    }

    return new Response(JSON.stringify({ error: "Unknown error occurred" }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
